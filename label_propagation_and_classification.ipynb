{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using label Propogation pipeline to label and classify mock data\n",
    "\n",
    "This notebook demonstrate how to use the label propagation code to label clothing data. The data used in this example is a Mock dataset randomly generated using the 100  most common words for each category in the actual data used in the paper that accompanies this work. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edd/.local/share/virtualenvs/labelpropagation_clothing-66lVHivS/lib/python3.6/site-packages/fuzzywuzzy/fuzz.py:35: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# Python imports\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "\n",
    "# plotting imports\n",
    "from matplotlib import pylab as plt\n",
    "import seaborn as sns\n",
    "%matplotlib notebook\n",
    "\n",
    "# scikit lean imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# NLP imports\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.metrics import distance\n",
    "\n",
    "# Custom imports of files to run label propagation pipeline\n",
    "import labelling_pipeline\n",
    "import Word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'labelling_pipeline' from '/home/edd/Documents/Projects/labelpropagation_clothing/labelling_pipeline.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(labelling_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "First read in the seed labels that will be used for fuzzy matching and label propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed labels\n",
    "with open('seed_labels.json', 'r') as f:\n",
    "    seed_labels = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read in the mock data to be labelled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df_mock = pd.read_csv('clothing_mock_data.csv',\n",
    "                      encoding=\"ISO-8859-1\",\n",
    "                      index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prevelance of items in the mock dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items for each label\n",
      "1104 items with label 0 \n",
      "434 items with label 1 \n",
      "393 items with label 2 \n",
      "75 items with label 3 \n",
      "576 items with label 4 \n",
      "514 items with label 5 \n",
      "395 items with label 6 \n",
      "243 items with label 7 \n",
      "261 items with label 8 \n"
     ]
    }
   ],
   "source": [
    "print('Number of items for each label')\n",
    "for lab in np.sort(df_mock.true_label.unique()):\n",
    "    print(\n",
    "        f\"{len(df_mock[df_mock['true_label'] == lab])} items with label {lab} \"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create a test train split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_mock.drop('true_label', axis=1),\n",
    "    df_mock['true_label'],\n",
    "    test_size=0.20,\n",
    "    stratify=df_mock['true_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of primary genders, categories \n",
    "This is used to help with selecting sub-set to match with and to clean the fuzzy matching to ensure maximum accuracy for the labels going into label propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender for each category\n",
    "divisions = [\n",
    "    'Womens', 'Men', 'Womens', 'Womens', 'Boys', 'Girls', 'Men', 'Men'\n",
    "]\n",
    "# broad categories for fuzzy matching cleaning\n",
    "categories = [\n",
    "    'Coats', 'Shirts', 'Fitness & activewear', 'Swim', 'Jeans', 'Tops',\n",
    "    'Underwear', 'Underwear'\n",
    "]\n",
    "\n",
    "# list of stopwords for use in word vectors\n",
    "stop = [\n",
    "    'pack', 'print', 'printed', 'sleeve', 'long', 'fit', 'f', 't', 's', 'asos',\n",
    "    'stripe', 'slim', 'running', 'active'\n",
    "]\n",
    "\n",
    "# names for output cleaned/labeled dataframes\n",
    "outs = ['coats', 'shirts', 'shorts', 'swim', 'jeans', 'tops', 'pants', 'socks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Label propogation for each category in turn \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the parameters used for fuzzy matching. \n",
    "\n",
    "Each matching method used requires a dictionary of the require parameters.\n",
    "\n",
    "These are put into a list to allow parameters for different methods to be run in the pipeline.\n",
    "\n",
    "The final fuzzy matched class for an is a modal (popular vote) decision from the result of all the methods used except in cases where one or more method shows a below the low threshold similarity (neg parameter), essentially a veto on the decision.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_list = [{\n",
    "    \"label\": \"label_fuz\",\n",
    "    \"func\": fuzz.partial_ratio,\n",
    "    \"thresh\": 0.70,\n",
    "    \"neg\": 0.25,\n",
    "    \"greater\": True,\n",
    "    \"less\": False\n",
    "}, {\n",
    "    \"label\": \"label_edit\",\n",
    "    \"func\": distance.edit_distance,\n",
    "    \"thresh\": 0.30,\n",
    "    \"neg\": 0.75,\n",
    "    \"greater\": False,\n",
    "    \"less\": True\n",
    "}, {\n",
    "    \"label\": \"label_jaccard\",\n",
    "    \"func\": distance.jaccard_distance,\n",
    "    \"thresh\": 0.30,\n",
    "    \"neg\": 0.75,\n",
    "    \"greater\": False,\n",
    "    \"less\": True\n",
    "}]\n",
    "\n",
    "word_vectorizer_params = {\n",
    "    \"epochs\": 200,\n",
    "    \"print_sim\": False,\n",
    "    \"ngram_range\": (1, 2),\n",
    "    \"doc2vec_thresh\": 0.5,\n",
    "    \"tfidf_thresh\": 0.5,\n",
    "    \"count_thresh\": 0.5,\n",
    "    \"fast_thresh\": 0.5,\n",
    "    \"word2vec_thresh\": 0.5,\n",
    "    \"doc2vec_params\": {\n",
    "        'alpha': 0.01,\n",
    "        'kernel': 'knn',\n",
    "        'n_neighbors': 6\n",
    "    },\n",
    "    \"tfidf_params\": {\n",
    "        'alpha': 0.01,\n",
    "        'kernel': 'knn',\n",
    "        'n_neighbors': 6\n",
    "    },\n",
    "    \"count_params\": {\n",
    "        'alpha': 0.01,\n",
    "        'kernel': 'knn',\n",
    "        'n_neighbors': 6\n",
    "    },\n",
    "    \"fast_params\": {\n",
    "        'alpha': 0.01,\n",
    "        'kernel': 'knn',\n",
    "        'n_neighbors': 6\n",
    "    },\n",
    "    \"word2vec_params\": {\n",
    "        'alpha': 0.01,\n",
    "        'kernel': 'knn',\n",
    "        'n_neighbors': 6\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**  coats\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2cd4bb85ee41dd82a85af9567bf578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Fuzzy matching in progress:', max=3, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edd/.local/share/virtualenvs/labelpropagation_clothing-66lVHivS/lib/python3.6/site-packages/pandas/core/indexing.py:337: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/edd/.local/share/virtualenvs/labelpropagation_clothing-66lVHivS/lib/python3.6/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f074b0b5c02142c191388776e6a33172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Computing vectors:', max=3, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b174ee972e4e95b0a6c639cfe1780a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Running label propagation', max=3, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edd/.local/share/virtualenvs/labelpropagation_clothing-66lVHivS/lib/python3.6/site-packages/sklearn/semi_supervised/label_propagation.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.label_distributions_ /= normalizer\n",
      "/home/edd/.local/share/virtualenvs/labelpropagation_clothing-66lVHivS/lib/python3.6/site-packages/pandas/core/indexing.py:337: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/edd/.local/share/virtualenvs/labelpropagation_clothing-66lVHivS/lib/python3.6/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-923e8b6f23db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mwv_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word2vec\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tfidf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"count\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         use_difflib=True)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mclean_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/labelpropagation_clothing/labelling_pipeline.py\u001b[0m in \u001b[0;36mlabelling_pipeline\u001b[0;34m(data, matching_params, word_vectorizer_params, n_words, names, stop_words, item_id, label_names, common_words, cat_clean, division, category, subcategory, wv_names, verbose, use_difflib)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label propagation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mcleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_label_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finding modal labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/labelpropagation_clothing/labelling_pipeline.py\u001b[0m in \u001b[0;36mrun_label_propagation\u001b[0;34m(embeddings_dict, cleaned)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mcleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'label_labprop_{key}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         cleaned.loc[label_mod.label_distributions_[:, 1] >= thresh,\n\u001b[0;32m--> 355\u001b[0;31m                     f'label_labprop_{key}'] = 1\n\u001b[0m\u001b[1;32m    356\u001b[0m         cleaned.loc[label_mod.label_distributions_[:, 0] >= thresh,\n\u001b[1;32m    357\u001b[0m                     f'label_labprop_{key}'] = 0\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "# parameters for the label propagation for each kind of word vector in tern\n",
    "param_doc2vec = {'alpha': 0.01, 'kernel': 'knn', 'n_neighbors': 6}\n",
    "param_tfidf = {'alpha': 0.01, 'kernel': 'knn', 'n_neighbors': 6}\n",
    "param_count = {'alpha': 0.01, 'kernel': 'knn', 'n_neighbors': 6}\n",
    "\n",
    "# empty dictinary to collect results of each category\n",
    "clean_frames = dict()\n",
    "\n",
    "# loop through the labelling pipeline for each output category\n",
    "for i in range(len(outs)):\n",
    "    print('\\n** ', outs[i])\n",
    "\n",
    "    # select only the correct gender - assume the gender column is reliabel\n",
    "\n",
    "    temp = X_train.loc[(X_train['division'] == divisions[i])]\n",
    "\n",
    "    # perform matching and cleaning\n",
    "    cleaned = labelling_pipeline.labelling_pipeline(\n",
    "        data=temp,\n",
    "        names=temp[\"name\"],\n",
    "        matching_params=matching_list,\n",
    "        word_vectorizer_params=word_vectorizer_params,\n",
    "        n_words=15,\n",
    "        stop_words=stop,\n",
    "        item_id=1,\n",
    "        label_names=seed_labels[str(i)],\n",
    "        common_words=True,\n",
    "        cat_clean=True,\n",
    "        division=divisions[i],\n",
    "        category=categories[i],\n",
    "        wv_names=(\"word2vec\", \"tfidf\", \"count\"),\n",
    "        verbose=True,\n",
    "        use_difflib=True)\n",
    "    \n",
    "    clean_frames[outs[i]] = cleaned\n",
    "\n",
    "print('labelled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the labels across iterations \n",
    "\n",
    "If a label is assigned in more than one loop it is assigned -1 for unlabelled\n",
    "If a label is assigned and then a 0 is also assigned the label outranks the 0\n",
    "If no label has been assigned ever then assume it is junk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine_labels for all categories\n",
    "label_dict={'other':0,'coats':1, 'shirts':2, 'shorts':3, 'swim':4, 'jeans':5, 'tops':6, 'pants':7, 'socks':8}\n",
    "\n",
    "X_train['label_combined'] = -10000\n",
    "X_train['lab_count'] =0 \n",
    "X_train['zero_count'] = 0\n",
    "\n",
    "# loop through the \n",
    "for i, frame in enumerate(list(clean_frames.keys())):\n",
    "    X_train[label_dict[frame]]=np.nan\n",
    "    index = clean_frames[frame].index\n",
    "    \n",
    "    X_train.loc[index, label_dict[frame]] = clean_frames[frame]['label_labprop_mode']\n",
    "    X_train.loc[(X_train[label_dict[frame]]==1), 'lab_count']+=1\n",
    "    X_train.loc[(X_train[label_dict[frame]]==0), 'zero_count']+=1\n",
    "    \n",
    "    X_train.loc[(X_train['lab_count']>1), 'label_combined']=-1\n",
    "    \n",
    "    X_train.loc[(X_train[label_dict[frame]]==1)&\n",
    "               (X_train['lab_count']==1), 'label_combined'] = label_dict[frame]\n",
    "    X_train.loc[(X_train[label_dict[frame]]==0)&\n",
    "               (X_train['zero_count']==i+1), 'label_combined'] = 0\n",
    "    X_train.loc[(X_train[label_dict[frame]]==-1)&\n",
    "               (X_train['lab_count']==0), 'label_combined']=-1\n",
    "    \n",
    "    X_train.loc[X_train['label_combined']==-10000, 'label_combined']=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the results of the label propagation pipeline\n",
    "\n",
    "**Numer of labels assigned**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of labels assigned: {len(X_train[X_train.label_combined>-1])}')\n",
    "print(f'Number of unlabelled items: {len(X_train[X_train.label_combined==-1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report for labelled items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train.loc[(X_train.label_combined>-1)],\n",
    "                            X_train.loc[(X_train.label_combined>-1),'label_combined']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix for labelled items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_train.loc[(X_train.label_combined>-1)],\n",
    "                       X_train.loc[(X_train.label_combined>-1),'label_combined'])\n",
    "fig,ax=plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(mat.T,square=True,annot=True,fmt='d',cbar=False)\n",
    "\n",
    "ax.set_yticklabels(['Junk','W Coats','M Casual Shirt', 'W sports shorts','W swim',\n",
    "               'B Jeans','G fashion top','M Underwear','M Socks'][::-1],rotation=45)\n",
    "\n",
    "ax.set_xticklabels(['Junk','W Coats','M Casual Shirt', 'W sports shorts','W swim',\n",
    "               'B Jeans','G fashion top','M Underwear','M Socks'],rotation=45)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted')\n",
    "\n",
    "ax.set_title('No Cleaning')\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Propogated')\n",
    "fig.tight_layout()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels have been propagated accuratly for most labels. This has not worked as well for the Mens Socks and Mens Pants categories. This is likely due to the shared language between socks and underwear as well as them falling in to the same broad category underwear. As this is a mock dataset the word order of the product names does not make sense and this may of impacted the quality of the fuzzy matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a classifiers\n",
    "\n",
    "Now we have the labelled data we can use it to train a classifier. \n",
    "In this example notebook we have only used the fastText vectors in the classifier it is quite easy to instead use other word vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create word vectors\n",
    "Want to create the word vectors from the largest possible vocabulary so use the whole mock dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get words for word_vectors\n",
    "names=Word_vectors.remove_stopwords(df_mock['name'])\n",
    "\n",
    "print('create models')\n",
    "\n",
    "print('tfidf')\n",
    "tfidf_mat,tf_mod = Word_vectors.TF_IDF(names.values, ngram_range=(1, 2),\n",
    "                                       print_sim=False,max_features=50)\n",
    "df_mock['tfidf'] = tfidf_mat.toarray().tolist()\n",
    "\n",
    "print('count_vec')\n",
    "count_mat,count_mod = Word_vectors.count_vectorizer(names.values, ngram_range=(1, 2),\n",
    "                                                    print_sim=False,max_features=50)\n",
    "df_mock['count_vec'] = count_mat.toarray().tolist()\n",
    "names\n",
    "ft_vectors, model_fasttext = Word_vectors.fasttext_vectors(names)\n",
    "df_mock['fasttext_vec'] = ft_vectors.tolist()\n",
    "\n",
    "w2v_vectors, model_w2v = Word_vectors.fit_word2vec(names)\n",
    "df_mock['w2v_vec'] = w2v_vectors.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Infer word vectors for labelled training data and the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Word_vectors)\n",
    "print('infer labelled data vectors')\n",
    "\n",
    "names_train=Word_vectors.remove_stopwords(X_train['name'])\n",
    "\n",
    "\n",
    "X_train['tfidf'] = tf_mod.transform(names_train).toarray().tolist()\n",
    "X_train['count_vec'] = count_mod.transform(names_train).toarray().tolist()\n",
    "X_train['fasttex']=Word_vectors.fasttext_infvec(names_train,model_fasttext).tolist()\n",
    "X_train['word2vec']=Word_vectors.word2vec(names_train,model_w2v).tolist()\n",
    "\n",
    "print('infer unlabelled vectors')\n",
    "names_test=Word_vectors.remove_stopwords(X_test['name'])\n",
    "    \n",
    "X_test['tfidf'] = tf_mod.transform(names_test).toarray().tolist()\n",
    "X_test['count_vec']=count_mod.transform(names_test).toarray().tolist()\n",
    "X_test['fasttex']=Word_vectors.fasttext_infvec(names_test,model_fasttext).tolist()\n",
    "X_test['word2vec']=Word_vectors.word2vec(names_test,model_w2v).tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create label encodings for the categorical columns division, category and and subcategory \n",
    "The encodings are created on the shole test data then applied to test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_code = LabelEncoder().fit(df_mock.division)\n",
    "cat_code = LabelEncoder().fit(df_mock.category)\n",
    "subcat_code = LabelEncoder().fit(df_mock.subcategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['division_code']=div_code.transform(X_train.division)\n",
    "X_train['category_code']=cat_code.transform(X_train.category)\n",
    "X_train['subcategory_code']=subcat_code.transform(X_train.subcategory)\n",
    "\n",
    "\n",
    "X_test['division_code']=div_code.transform(X_test.division)\n",
    "X_test['category_code']=cat_code.transform(X_test.category)\n",
    "X_test['subcategory_code']=subcat_code.transform(X_test.subcategory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training dataset with only the products assigned a label, not -1 prodcuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled=X_train[X_train['label_combined']>-1]\n",
    "labelled_y=y_train[X_train['label_combined']>-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need to stack together all the inputs for the classifiers inorder to use the word vectors with the categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack X train inputs\n",
    "X_train_in = np.stack(labelled[['division_code', 'category_code', 'subcategory_code']].values)\n",
    "X_train_in = np.concatenate((X_train_in,np.stack(labelled['fasttex'])),axis=1)\n",
    "\n",
    "\n",
    "# # stack unlabelled inputs \n",
    "X_test_in = np.stack(X_test[['division_code', 'category_code', 'subcategory_code']].values)\n",
    "X_test_in = np.concatenate((X_test_in,np.stack(X_test['fasttex'])),axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "Build a decision tree with the fastText vectors. No rigourious hyper-parameter search has been undertaken only a basic grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_grid = [{'max_depth':[5,10,20,30,50],'min_samples_leaf':[5,10,15,20,25],'min_samples_split':[2,5,7,10,20]}]\n",
    "dt_clf = GridSearchCV(estimator= DecisionTreeClassifier(class_weight='balanced'),param_grid=param_grid,cv=5)\n",
    "dt_clf.fit(X_train_in,labelled['label_combined'])\n",
    "\n",
    "dt_params = dt_clf.best_params_\n",
    "\n",
    "print(f'Best fit parameters: {dt_params}')\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(**dt_params)\n",
    "dt_clf.fit(X_train_in,labelled['label_combined'])\n",
    "\n",
    "ind = np.argsort(dt_clf.feature_importances_)[::-1]\n",
    "\n",
    "print('\\n*** Training labelled data set against true labels***')\n",
    "\n",
    "print(classification_report(labelled_y,dt_clf.predict(X_train_in)))\n",
    "\n",
    "\n",
    "predict_dt=dt_clf.predict(X_test_in)\n",
    "print('\\n*** Test split of labelled data set ***')\n",
    "print(classification_report(y_test,predict_dt))\n",
    "\n",
    "mat = confusion_matrix(y_test,predict_dt)\n",
    "fig,ax=plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(mat.T,square=True,annot=True,fmt='d',cbar=False)\n",
    "ax.set_yticklabels(['Junk','W Coats','M Casual Shirt', 'W sports shorts','W swim',\n",
    "               'B Jeans','G fashion top','M Underwear','M Socks'][::-1],rotation=45)\n",
    "\n",
    "ax.set_xticklabels(['Junk','W Coats','M Casual Shirt', 'W sports shorts','W swim',\n",
    "               'B Jeans','G fashion top','M Underwear','M Socks'],rotation=45)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree works reasonaly well with the poorly performing items being the same as those that did not perform so well in propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Build a random forest with the fastText vectors. No rigourious hyper-parameter search has been undertaken only a basic grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'n_estimators':[5,10,20,30,50],'max_depth':[5,10,20,30,50,100],'min_samples_leaf':[1,3,5,10,15]}]\n",
    "rf_clf = GridSearchCV(estimator= RandomForestClassifier(class_weight='balanced'),param_grid=param_grid,cv=5)\n",
    "rf_clf.fit(X_train_in,labelled['label_combined'])\n",
    "rf_parm = rf_clf.best_params_\n",
    "\n",
    "print(f'Best fit parameters: {dt_params}')\n",
    "\n",
    "rf_clf = RandomForestClassifier(**rf_parm,class_weight='balanced') #max_depth=10,min_samples_leaf=5)\n",
    "rf_clf.fit(X_train_in,labelled['label_combined'])\n",
    "\n",
    "\n",
    "print('\\n*** Training labelled data set against true labels***')\n",
    "print(classification_report(labelled_y,rf_clf.predict(X_train_in)))\n",
    "\n",
    "\n",
    "predict_rf=rf_clf.predict(X_test_in)\n",
    "print('\\n*** Test split of labelled data set ***')\n",
    "print(classification_report(y_test,predict_rf))\n",
    "\n",
    "mat = confusion_matrix(y_test,predict_rf)\n",
    "fig,ax=plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(mat.T,square=True,annot=True,fmt='d',cbar=False)\n",
    "ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted')\n",
    "\n",
    "predict_rf=rf_clf.predict(X_test_in)\n",
    "\n",
    "ax.set_yticklabels(['Junk','W Coats','M Casual Shirt', 'W sports shorts','W swim',\n",
    "               'B Jeans','G fashion top','M Underwear','M Socks'][::-1],rotation=45)\n",
    "\n",
    "ax.set_xticklabels(['Junk','W Coats','M Casual Shirt', 'W sports shorts','W swim',\n",
    "               'B Jeans','G fashion top','M Underwear','M Socks'],rotation=45)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted')\n",
    "fig.tight_layout()\n",
    "# fig.savefig('fasttext_rf_confusion.png')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest is performing better accross most categories but is unable to distinguish socks and underwear. Aain this is where the label propagation performed worse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suport vector machine\n",
    "\n",
    "Build a SVM with the fastText vectors. No rigourious hyper-parameter search has been undertaken only a basic grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_grid = [{'C':[10,100,1000,2000,5000,10000,20000],'gamma':[0.0,0.00001,0.00005,0.0001,0.01],'kernel':['rbf']}]\n",
    "\n",
    "svm_clf = GridSearchCV(estimator=SVC(probability=True),param_grid=param_grid,cv=5)\n",
    "svm_clf.fit(X_train_in,labelled['label_combined'])\n",
    "svm_param = svm_clf.best_params_\n",
    "print(f\"Best fit parameters: {dt_params}\")\n",
    "\n",
    "svm_clf = SVC(**svm_param, probability=True) #max_depth=10,min_samples_leaf=5)\n",
    "svm_clf.fit(X_train_in,labelled['label_combined'])\n",
    "\n",
    "predict_svm=svm_clf.predict(X_test_in)\n",
    "\n",
    "print('\\n*** Training labelled data set against true labels***')\n",
    "print(classification_report(labelled_y,svm_clf.predict(X_train_in)))\n",
    "\n",
    "\n",
    "print('\\n*** Test split of labelled data set ***')\n",
    "print(classification_report(y_test,predict_svm))\n",
    "\n",
    "mat = confusion_matrix(y_test,predict_svm)\n",
    "fig,ax=plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(mat.T,square=True,annot=True,fmt='d',cbar=False)\n",
    "ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted')\n",
    "\n",
    "predict_proba=svm_clf.predict_proba(X_test_in)\n",
    "\n",
    "\n",
    "ax.set_yticklabels(['Junk','W Coats','M Casual Shirt', 'W sports shorts','W swim',\n",
    "               'B Jeans','G fashion top','M Underwear','M Socks'][::-1],rotation=45)\n",
    "\n",
    "ax.set_xticklabels(['Junk','W Coats','M Casual Shirt', 'W sports shorts','W swim',\n",
    "               'B Jeans','G fashion top','M Underwear','M Socks'],rotation=45)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM has given similar results to the decision tree, performing very well except where the label propagation has done poorly.\n",
    "\n",
    "\n",
    "This notebook is intended to demonstate the methods of paper Semi-supervised machine learning with word embedding for classification in price statistics, Martindale et.al. using a mock dataset. \n",
    "We are not attempting to recreate the results of the paper as we can not make the data publicly avalible instead the mock dataset gives a demonstataion of the code. We do however see generally similar trends as with the true data. For more methods data see the paper.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labelpropagation_clothing",
   "language": "python",
   "name": "labelpropagation_clothing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
